{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset\n",
    "data1 = pd.read_csv('MachineLearningCVE/Monday-WorkingHours.pcap_ISCX.csv')\n",
    "#data2 = pd.read_csv('MachineLearningCVE/Tuesday-WorkingHours.pcap_ISCX.csv')\n",
    "#data3 = pd.read_csv('MachineLearningCVE/Wednesday-workingHours.pcap_ISCX.csv')\n",
    "data4 = pd.read_csv('MachineLearningCVE/Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv')\n",
    "#data5 = pd.read_csv('MachineLearningCVE/Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv')\n",
    "#data6 = pd.read_csv('MachineLearningCVE/Friday-WorkingHours-Morning.pcap_ISCX.csv')\n",
    "data7 = pd.read_csv('MachineLearningCVE/Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv')\n",
    "#data8 = pd.read_csv('MachineLearningCVE/Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data dimensions: \n",
      "Data1 -> 529918 rows, 79 columns\n",
      "Data2 -> 170366 rows, 79 columns\n",
      "Data3 -> 286467 rows, 79 columns\n"
     ]
    }
   ],
   "source": [
    "data_list = [data1,data4,data7]\n",
    "\n",
    "print('Data dimensions: ')\n",
    "for i, data in enumerate(data_list, start = 1):\n",
    "  rows, cols = data.shape\n",
    "  print(f'Data{i} -> {rows} rows, {cols} columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New dimension:\n",
      "Number of rows: 986751\n",
      "Number of columns: 79\n",
      "Total cells: 77953329\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat(data_list)\n",
    "rows, cols = df.shape\n",
    "\n",
    "print('New dimension:')\n",
    "print(f'Number of rows: {rows}')\n",
    "print(f'Number of columns: {cols}')\n",
    "print(f'Total cells: {rows * cols}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting dataframes after concating to save memory\n",
    "for d in data_list: del d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming the columns by removing leading/trailing whitespace\n",
    "col_names = {col: col.strip() for col in df.columns}\n",
    "df.rename(columns = col_names, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Destination Port', 'Flow Duration', 'Total Fwd Packets',\n",
      "       'Total Backward Packets', 'Total Length of Fwd Packets',\n",
      "       'Total Length of Bwd Packets', 'Fwd Packet Length Max',\n",
      "       'Fwd Packet Length Min', 'Fwd Packet Length Mean',\n",
      "       'Fwd Packet Length Std', 'Bwd Packet Length Max',\n",
      "       'Bwd Packet Length Min', 'Bwd Packet Length Mean',\n",
      "       'Bwd Packet Length Std', 'Flow Bytes/s', 'Flow Packets/s',\n",
      "       'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max', 'Flow IAT Min',\n",
      "       'Fwd IAT Total', 'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max',\n",
      "       'Fwd IAT Min', 'Bwd IAT Total', 'Bwd IAT Mean', 'Bwd IAT Std',\n",
      "       'Bwd IAT Max', 'Bwd IAT Min', 'Fwd PSH Flags', 'Bwd PSH Flags',\n",
      "       'Fwd URG Flags', 'Bwd URG Flags', 'Fwd Header Length',\n",
      "       'Bwd Header Length', 'Fwd Packets/s', 'Bwd Packets/s',\n",
      "       'Min Packet Length', 'Max Packet Length', 'Packet Length Mean',\n",
      "       'Packet Length Std', 'Packet Length Variance', 'FIN Flag Count',\n",
      "       'SYN Flag Count', 'RST Flag Count', 'PSH Flag Count', 'ACK Flag Count',\n",
      "       'URG Flag Count', 'CWE Flag Count', 'ECE Flag Count', 'Down/Up Ratio',\n",
      "       'Average Packet Size', 'Avg Fwd Segment Size', 'Avg Bwd Segment Size',\n",
      "       'Fwd Header Length.1', 'Fwd Avg Bytes/Bulk', 'Fwd Avg Packets/Bulk',\n",
      "       'Fwd Avg Bulk Rate', 'Bwd Avg Bytes/Bulk', 'Bwd Avg Packets/Bulk',\n",
      "       'Bwd Avg Bulk Rate', 'Subflow Fwd Packets', 'Subflow Fwd Bytes',\n",
      "       'Subflow Bwd Packets', 'Subflow Bwd Bytes', 'Init_Win_bytes_forward',\n",
      "       'Init_Win_bytes_backward', 'act_data_pkt_fwd', 'min_seg_size_forward',\n",
      "       'Active Mean', 'Active Std', 'Active Max', 'Active Min', 'Idle Mean',\n",
      "       'Idle Std', 'Idle Max', 'Idle Min', 'Label'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features from labels\n",
    "X = df.drop(columns=['Label'])\n",
    "y = df['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (985808, 78)\n",
      "Unique labels in y: [0 1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "# Replace ±∞ with NaN\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Suppose the dataset has a 'Label' column\n",
    "df['Label'] = df['Label'].astype('category').cat.codes\n",
    "\n",
    "# Separate features & labels\n",
    "X = df.drop(columns=['Label'])\n",
    "y = df['Label'].values\n",
    "\n",
    "print(\"Features shape:\", X.shape)\n",
    "print(\"Unique labels in y:\", np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (690064, 78) (690064,)\n",
      "Val:   (147872, 78) (147872,)\n",
      "Test:  (147872, 78) (147872,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.15, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "val_ratio = 0.15 / 0.85\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_val, y_train_val, test_size=val_ratio, \n",
    "    random_state=42, stratify=y_train_val\n",
    ")\n",
    "\n",
    "print(\"Train:\", X_train.shape, y_train.shape)\n",
    "print(\"Val:  \", X_val.shape, y_val.shape)\n",
    "print(\"Test: \", X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Justification for 70-15-15 split:\n",
    "\n",
    "70% Training: Enough data to learn robust patterns.\n",
    "\n",
    "15% Validation: A separate set for hyperparameter tuning (e.g., learning rate, noise multiplier for DP, etc.).\n",
    "\n",
    "15% Test: Kept strictly for final evaluation. This prevents overfitting to the validation set and provides an unbiased measure of performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install torch opacus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from opacus import PrivacyEngine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to PyTorch tensors\n",
    "X_train_t = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_t = torch.tensor(y_train, dtype=torch.long)\n",
    "\n",
    "X_val_t = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val_t = torch.tensor(y_val, dtype=torch.long)\n",
    "\n",
    "X_test_t = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_t = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_t, y_train_t)\n",
    "val_dataset   = TensorDataset(X_val_t,   y_val_t)\n",
    "test_dataset  = TensorDataset(X_test_t,  y_test_t)\n",
    "\n",
    "batch_size = 256\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=batch_size, shuffle=False)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=64, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, num_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "num_classes = len(np.unique(y_train))  # If it's binary, likely 2\n",
    "model = SimpleMLP(input_dim, hidden_dim=64, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\poly\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\opacus\\privacy_engine.py:96: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# DP hyperparameters\n",
    "noise_multiplier = 1.0\n",
    "max_grad_norm = 1.0\n",
    "epochs = 5\n",
    "delta = 1e-5\n",
    "\n",
    "privacy_engine = PrivacyEngine()\n",
    "\n",
    "model, optimizer, train_loader = privacy_engine.make_private(\n",
    "    module=model,\n",
    "    optimizer=optimizer,\n",
    "    data_loader=train_loader,\n",
    "    noise_multiplier=noise_multiplier,\n",
    "    max_grad_norm=max_grad_norm,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\poly\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1830: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 0.2455, Acc: 0.9184\n",
      "Epoch [2/5], Loss: 0.0474, Acc: 0.9907\n",
      "Epoch [3/5], Loss: 0.0496, Acc: 0.9919\n",
      "Epoch [4/5], Loss: 0.0499, Acc: 0.9923\n",
      "Epoch [5/5], Loss: 0.0495, Acc: 0.9924\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct, total = 0, 0\n",
    "    \n",
    "    for data, target in train_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * data.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == target).sum().item()\n",
    "        total += target.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc  = correct / total\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9920945141744211\n",
      "Precision: 0.9899418263051223\n",
      "Recall: 0.9920877515689245\n",
      "F1-Score: 0.9910042453351676\n",
      "Confusion Matrix:\n",
      " [[123107    617      0      0      0]\n",
      " [   226  23595      0      0      0]\n",
      " [   226      0      0      0      0]\n",
      " [     3      0      0      0      0]\n",
      " [    98      0      0      0      0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\poly\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import (\n",
    "    confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score\n",
    ")\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    all_probs = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            outputs = model(data)\n",
    "            \n",
    "            # If multi-class, outputs have shape [batch_size, num_classes]\n",
    "            probs = torch.softmax(outputs, dim=1)[:,1]  # Probability of class=1\n",
    "            all_probs.append(probs.cpu().numpy())\n",
    "            all_labels.append(target.cpu().numpy())\n",
    "            \n",
    "            _, pred = torch.max(outputs, 1)\n",
    "            correct += (pred == target).sum().item()\n",
    "            total += target.size(0)\n",
    "    acc = correct / total\n",
    "    return acc, np.concatenate(all_probs), np.concatenate(all_labels)\n",
    "\n",
    "test_acc, y_prob_test, y_test_true = evaluate(model, test_loader)\n",
    "print(\"Test Accuracy:\", test_acc)\n",
    "\n",
    "y_pred_test = (y_prob_test >= 0.5).astype(int)\n",
    "\n",
    "prec = precision_score(y_test_true, y_pred_test,average='weighted')\n",
    "rec  = recall_score(y_test_true, y_pred_test,average='weighted')\n",
    "f1   = f1_score(y_test_true, y_pred_test,average='weighted')\n",
    "cm   = confusion_matrix(y_test_true, y_pred_test)\n",
    "\n",
    "print(\"Precision:\", prec)\n",
    "print(\"Recall:\", rec)\n",
    "print(\"F1-Score:\", f1)\n",
    "print(\"Confusion Matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ε = 0.20 for δ = 1e-05\n"
     ]
    }
   ],
   "source": [
    "epsilon = privacy_engine.get_epsilon(delta=delta)\n",
    "print(f\"ε = {epsilon:.2f} for δ = {delta}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flwr\n",
      "  Downloading flwr-1.16.0-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: opacus in c:\\users\\poly\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.5.3)\n",
      "Collecting cryptography<45.0.0,>=44.0.1 (from flwr)\n",
      "  Downloading cryptography-44.0.2-cp39-abi3-win_amd64.whl.metadata (5.7 kB)\n",
      "Collecting grpcio!=1.65.0,<2.0.0,>=1.62.3 (from flwr)\n",
      "  Downloading grpcio-1.71.0-cp313-cp313-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting iterators<0.0.3,>=0.0.2 (from flwr)\n",
      "  Downloading iterators-0.0.2-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.26.0 in c:\\users\\poly\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from flwr) (1.26.4)\n",
      "Collecting pathspec<0.13.0,>=0.12.1 (from flwr)\n",
      "  Downloading pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting protobuf<5.0.0,>=4.21.6 (from flwr)\n",
      "  Using cached protobuf-4.25.6-cp310-abi3-win_amd64.whl.metadata (541 bytes)\n",
      "Collecting pycryptodome<4.0.0,>=3.18.0 (from flwr)\n",
      "  Downloading pycryptodome-3.21.0-cp36-abi3-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting pyyaml<7.0.0,>=6.0.2 (from flwr)\n",
      "  Downloading PyYAML-6.0.2-cp313-cp313-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting requests<3.0.0,>=2.31.0 (from flwr)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting rich<14.0.0,>=13.5.0 (from flwr)\n",
      "  Using cached rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting tomli<3.0.0,>=2.0.1 (from flwr)\n",
      "  Downloading tomli-2.2.1-cp313-cp313-win_amd64.whl.metadata (12 kB)\n",
      "Collecting tomli-w<2.0.0,>=1.0.0 (from flwr)\n",
      "  Downloading tomli_w-1.2.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting typer<0.13.0,>=0.12.5 (from flwr)\n",
      "  Downloading typer-0.12.5-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: torch>=2.0 in c:\\users\\poly\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from opacus) (2.6.0)\n",
      "Requirement already satisfied: scipy>=1.2 in c:\\users\\poly\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from opacus) (1.15.1)\n",
      "Requirement already satisfied: opt-einsum>=3.3.0 in c:\\users\\poly\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from opacus) (3.4.0)\n",
      "Collecting cffi>=1.12 (from cryptography<45.0.0,>=44.0.1->flwr)\n",
      "  Downloading cffi-1.17.1-cp313-cp313-win_amd64.whl.metadata (1.6 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3.0.0,>=2.31.0->flwr)\n",
      "  Downloading charset_normalizer-3.4.1-cp313-cp313-win_amd64.whl.metadata (36 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3.0.0,>=2.31.0->flwr)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3.0.0,>=2.31.0->flwr)\n",
      "  Downloading urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3.0.0,>=2.31.0->flwr)\n",
      "  Downloading certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich<14.0.0,>=13.5.0->flwr)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\poly\\appdata\\roaming\\python\\python313\\site-packages (from rich<14.0.0,>=13.5.0->flwr) (2.19.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\poly\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=2.0->opacus) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\poly\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=2.0->opacus) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\poly\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=2.0->opacus) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\poly\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=2.0->opacus) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\poly\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=2.0->opacus) (2025.3.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\poly\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=2.0->opacus) (76.0.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\poly\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=2.0->opacus) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\poly\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sympy==1.13.1->torch>=2.0->opacus) (1.3.0)\n",
      "Collecting click>=8.0.0 (from typer<0.13.0,>=0.12.5->flwr)\n",
      "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer<0.13.0,>=0.12.5->flwr)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting pycparser (from cffi>=1.12->cryptography<45.0.0,>=44.0.1->flwr)\n",
      "  Downloading pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Requirement already satisfied: colorama in c:\\users\\poly\\appdata\\roaming\\python\\python313\\site-packages (from click>=8.0.0->typer<0.13.0,>=0.12.5->flwr) (0.4.6)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.5.0->flwr)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\poly\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jinja2->torch>=2.0->opacus) (3.0.2)\n",
      "Downloading flwr-1.16.0-py3-none-any.whl (532 kB)\n",
      "   ---------------------------------------- 0.0/532.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 532.1/532.1 kB 9.2 MB/s eta 0:00:00\n",
      "Downloading cryptography-44.0.2-cp39-abi3-win_amd64.whl (3.2 MB)\n",
      "   ---------------------------------------- 0.0/3.2 MB ? eta -:--:--\n",
      "   ----------------------------------- ---- 2.9/3.2 MB 14.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.2/3.2 MB 12.6 MB/s eta 0:00:00\n",
      "Downloading grpcio-1.71.0-cp313-cp313-win_amd64.whl (4.3 MB)\n",
      "   ---------------------------------------- 0.0/4.3 MB ? eta -:--:--\n",
      "   ------------------------ --------------- 2.6/4.3 MB 12.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.3/4.3 MB 11.6 MB/s eta 0:00:00\n",
      "Downloading iterators-0.0.2-py3-none-any.whl (3.9 kB)\n",
      "Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
      "Using cached protobuf-4.25.6-cp310-abi3-win_amd64.whl (413 kB)\n",
      "Downloading pycryptodome-3.21.0-cp36-abi3-win_amd64.whl (1.8 MB)\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.8/1.8 MB 11.0 MB/s eta 0:00:00\n",
      "Downloading PyYAML-6.0.2-cp313-cp313-win_amd64.whl (156 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Downloading tomli-2.2.1-cp313-cp313-win_amd64.whl (109 kB)\n",
      "Downloading tomli_w-1.2.0-py3-none-any.whl (6.7 kB)\n",
      "Downloading typer-0.12.5-py3-none-any.whl (47 kB)\n",
      "Downloading certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "Downloading cffi-1.17.1-cp313-cp313-win_amd64.whl (182 kB)\n",
      "Downloading charset_normalizer-3.4.1-cp313-cp313-win_amd64.whl (102 kB)\n",
      "Downloading click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "Installing collected packages: urllib3, tomli-w, tomli, shellingham, pyyaml, pycryptodome, pycparser, protobuf, pathspec, mdurl, iterators, idna, grpcio, click, charset-normalizer, certifi, requests, markdown-it-py, cffi, rich, cryptography, typer, flwr\n",
      "Successfully installed certifi-2025.1.31 cffi-1.17.1 charset-normalizer-3.4.1 click-8.1.8 cryptography-44.0.2 flwr-1.16.0 grpcio-1.71.0 idna-3.10 iterators-0.0.2 markdown-it-py-3.0.0 mdurl-0.1.2 pathspec-0.12.1 protobuf-4.25.6 pycparser-2.22 pycryptodome-3.21.0 pyyaml-6.0.2 requests-2.32.3 rich-13.9.4 shellingham-1.5.4 tomli-2.2.1 tomli-w-1.2.0 typer-0.12.5 urllib3-2.3.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#%pip install flwr opacus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. \n",
      "\tInstead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: \n",
      "\tflwr.client.start_client(\n",
      "\t\tserver_address='<IP>:<PORT>',\n",
      "\t\tclient=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object\n",
      "\t)\n",
      "\tUsing `start_numpy_client()` is deprecated.\n",
      "\n",
      "            This is a deprecated feature. It will be removed\n",
      "            entirely in future versions of Flower.\n",
      "        \n",
      "03/12/2025 17:37:44:WARNING:DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. \n",
      "\tInstead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: \n",
      "\tflwr.client.start_client(\n",
      "\t\tserver_address='<IP>:<PORT>',\n",
      "\t\tclient=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object\n",
      "\t)\n",
      "\tUsing `start_numpy_client()` is deprecated.\n",
      "\n",
      "            This is a deprecated feature. It will be removed\n",
      "            entirely in future versions of Flower.\n",
      "        \n",
      "\u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.\n",
      "\tInstead, use the `flower-supernode` CLI command to start a SuperNode as shown below:\n",
      "\n",
      "\t\t$ flower-supernode --insecure --superlink='<IP>:<PORT>'\n",
      "\n",
      "\tTo view all available options, run:\n",
      "\n",
      "\t\t$ flower-supernode --help\n",
      "\n",
      "\tUsing `start_client()` is deprecated.\n",
      "\n",
      "            This is a deprecated feature. It will be removed\n",
      "            entirely in future versions of Flower.\n",
      "        \n",
      "03/12/2025 17:37:44:WARNING:DEPRECATED FEATURE: flwr.client.start_client() is deprecated.\n",
      "\tInstead, use the `flower-supernode` CLI command to start a SuperNode as shown below:\n",
      "\n",
      "\t\t$ flower-supernode --insecure --superlink='<IP>:<PORT>'\n",
      "\n",
      "\tTo view all available options, run:\n",
      "\n",
      "\t\t$ flower-supernode --help\n",
      "\n",
      "\tUsing `start_client()` is deprecated.\n",
      "\n",
      "            This is a deprecated feature. It will be removed\n",
      "            entirely in future versions of Flower.\n",
      "        \n",
      "03/12/2025 17:37:44:DEBUG:Opened insecure gRPC connection (no certificates were passed)\n",
      "03/12/2025 17:37:44:DEBUG:ChannelConnectivity.IDLE\n",
      "03/12/2025 17:37:44:DEBUG:ChannelConnectivity.CONNECTING\n",
      "03/12/2025 17:37:46:DEBUG:ChannelConnectivity.TRANSIENT_FAILURE\n",
      "03/12/2025 17:37:47:DEBUG:gRPC channel closed\n"
     ]
    },
    {
     "ename": "_MultiThreadedRendezvous",
     "evalue": "<_MultiThreadedRendezvous of RPC that terminated with:\n\tstatus = StatusCode.UNAVAILABLE\n\tdetails = \"failed to connect to all addresses; last error: UNAVAILABLE: ipv4:127.0.0.1:8080: ConnectEx: Connection refused (No connection could be made because the target machine actively refused it.\r\n -- 10061)\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer  {grpc_message:\"failed to connect to all addresses; last error: UNAVAILABLE: ipv4:127.0.0.1:8080: ConnectEx: Connection refused (No connection could be made because the target machine actively refused it.\\r\\n -- 10061)\", grpc_status:14, created_time:\"2025-03-12T21:37:46.8568111+00:00\"}\"\n>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_MultiThreadedRendezvous\u001b[0m                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 129\u001b[0m\n\u001b[0;32m    126\u001b[0m     fl\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mstart_numpy_client(server_address\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocalhost:8080\u001b[39m\u001b[38;5;124m\"\u001b[39m, client\u001b[38;5;241m=\u001b[39mclient)\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 129\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[39], line 126\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    123\u001b[0m model \u001b[38;5;241m=\u001b[39m SimpleMLP(input_dim\u001b[38;5;241m=\u001b[39minput_dim, hidden_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, num_classes\u001b[38;5;241m=\u001b[39mnum_classes)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m    125\u001b[0m client \u001b[38;5;241m=\u001b[39m FLClient(model, train_loader, val_loader, device)\n\u001b[1;32m--> 126\u001b[0m \u001b[43mfl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_numpy_client\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserver_address\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlocalhost:8080\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\poly\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\flwr\\client\\app.py:729\u001b[0m, in \u001b[0;36mstart_numpy_client\u001b[1;34m(server_address, client, grpc_max_message_length, root_certificates, insecure, transport)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;66;03m# Calling this function is deprecated. A warning is thrown.\u001b[39;00m\n\u001b[0;32m    725\u001b[0m \u001b[38;5;66;03m# We first need to convert the supplied client to `Client.`\u001b[39;00m\n\u001b[0;32m    727\u001b[0m wrp_client \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mto_client()\n\u001b[1;32m--> 729\u001b[0m \u001b[43mstart_client\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    730\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserver_address\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    731\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwrp_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    732\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrpc_max_message_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrpc_max_message_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    733\u001b[0m \u001b[43m    \u001b[49m\u001b[43mroot_certificates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mroot_certificates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    734\u001b[0m \u001b[43m    \u001b[49m\u001b[43minsecure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minsecure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    735\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransport\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransport\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    736\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\poly\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\flwr\\client\\app.py:201\u001b[0m, in \u001b[0;36mstart_client\u001b[1;34m(server_address, client_fn, client, grpc_max_message_length, root_certificates, insecure, transport, authentication_keys, max_retries, max_wait_time)\u001b[0m\n\u001b[0;32m    198\u001b[0m warn_deprecated_feature(name\u001b[38;5;241m=\u001b[39mmsg)\n\u001b[0;32m    200\u001b[0m event(EventType\u001b[38;5;241m.\u001b[39mSTART_CLIENT_ENTER)\n\u001b[1;32m--> 201\u001b[0m \u001b[43mstart_client_internal\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserver_address\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnode_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[43mload_client_app_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    205\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    207\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrpc_max_message_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrpc_max_message_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    208\u001b[0m \u001b[43m    \u001b[49m\u001b[43mroot_certificates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mroot_certificates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    209\u001b[0m \u001b[43m    \u001b[49m\u001b[43minsecure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minsecure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    210\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransport\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransport\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    211\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauthentication_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauthentication_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    212\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    213\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_wait_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_wait_time\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    215\u001b[0m event(EventType\u001b[38;5;241m.\u001b[39mSTART_CLIENT_LEAVE)\n",
      "File \u001b[1;32mc:\\Users\\poly\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\flwr\\client\\app.py:438\u001b[0m, in \u001b[0;36mstart_client_internal\u001b[1;34m(server_address, node_config, load_client_app_fn, client_fn, client, grpc_max_message_length, root_certificates, insecure, transport, authentication_keys, max_retries, max_wait_time, flwr_path, isolation, clientappio_api_address)\u001b[0m\n\u001b[0;32m    435\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    436\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    437\u001b[0m         \u001b[38;5;66;03m# Receive\u001b[39;00m\n\u001b[1;32m--> 438\u001b[0m         message \u001b[38;5;241m=\u001b[39m \u001b[43mreceive\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    439\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m message \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    440\u001b[0m             time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m3\u001b[39m)  \u001b[38;5;66;03m# Wait for 3s before asking again\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\poly\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\flwr\\client\\grpc_client\\connection.py:140\u001b[0m, in \u001b[0;36mgrpc_connection.<locals>.receive\u001b[1;34m()\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mreceive\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Message:\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;66;03m# Receive ServerMessage proto\u001b[39;00m\n\u001b[1;32m--> 140\u001b[0m     proto \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mserver_message_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;66;03m# ServerMessage proto --> *Ins --> RecordSet\u001b[39;00m\n\u001b[0;32m    143\u001b[0m     field \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mWhichOneof(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmsg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\poly\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\grpc\\_channel.py:543\u001b[0m, in \u001b[0;36m_Rendezvous.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    542\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 543\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\poly\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\grpc\\_channel.py:969\u001b[0m, in \u001b[0;36m_MultiThreadedRendezvous._next\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    967\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m()\n\u001b[0;32m    968\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state\u001b[38;5;241m.\u001b[39mcode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 969\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[1;31m_MultiThreadedRendezvous\u001b[0m: <_MultiThreadedRendezvous of RPC that terminated with:\n\tstatus = StatusCode.UNAVAILABLE\n\tdetails = \"failed to connect to all addresses; last error: UNAVAILABLE: ipv4:127.0.0.1:8080: ConnectEx: Connection refused (No connection could be made because the target machine actively refused it.\r\n -- 10061)\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer  {grpc_message:\"failed to connect to all addresses; last error: UNAVAILABLE: ipv4:127.0.0.1:8080: ConnectEx: Connection refused (No connection could be made because the target machine actively refused it.\\r\\n -- 10061)\", grpc_status:14, created_time:\"2025-03-12T21:37:46.8568111+00:00\"}\"\n>"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import flwr as fl\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from opacus import PrivacyEngine\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define the model\n",
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=64, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# Define the Flower client\n",
    "class FLClient(fl.client.NumPyClient):\n",
    "    def __init__(self, model, train_loader, val_loader, device):\n",
    "        self.model = model\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.device = device\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.optimizer = optim.SGD(self.model.parameters(), lr=0.01)\n",
    "\n",
    "        # Initialize Opacus\n",
    "        self.privacy_engine = PrivacyEngine()\n",
    "\n",
    "        # Make the model and optimizer \"private\"\n",
    "        self.model, self.optimizer, self.train_loader = self.privacy_engine.make_private(\n",
    "            module=self.model,\n",
    "            optimizer=self.optimizer,\n",
    "            data_loader=self.train_loader,\n",
    "            noise_multiplier=1.0,\n",
    "            max_grad_norm=1.0,\n",
    "        )\n",
    "\n",
    "    def get_parameters(self):\n",
    "        return [val.cpu().numpy() for _, val in self.model.state_dict().items()]\n",
    "\n",
    "    def set_parameters(self, parameters):\n",
    "        params_dict = zip(self.model.state_dict().keys(), parameters)\n",
    "        state_dict = {k: torch.tensor(v) for k, v in params_dict}\n",
    "        self.model.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        self.set_parameters(parameters)\n",
    "        self.model.train()\n",
    "        for _ in range(1):  # One epoch\n",
    "            for data, target in self.train_loader:\n",
    "                data, target = data.to(self.device), target.to(self.device)\n",
    "                self.optimizer.zero_grad()\n",
    "                output = self.model(data)\n",
    "                loss = self.criterion(output, target)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "        return self.get_parameters(), len(self.train_loader.dataset), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        self.set_parameters(parameters)\n",
    "        self.model.eval()\n",
    "        loss = 0.0\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for data, target in self.val_loader:\n",
    "                data, target = data.to(self.device), target.to(self.device)\n",
    "                output = self.model(data)\n",
    "                loss += self.criterion(output, target).item()\n",
    "                pred = output.argmax(dim=1, keepdim=True)\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        loss /= len(self.val_loader.dataset)\n",
    "        accuracy = correct / len(self.val_loader.dataset)\n",
    "        return float(loss), len(self.val_loader.dataset), {\"accuracy\": float(accuracy)}\n",
    "\n",
    "# Example data loading\n",
    "def load_data():\n",
    "    \"\"\"\n",
    "    Replace this dummy data logic with your actual data loading and preprocessing.\n",
    "    X_train, y_train, X_val, y_val should be numpy arrays (or easily convertible to tensors).\n",
    "    \"\"\"\n",
    "    # For demonstration, generate a small random dataset\n",
    "    np.random.seed(42)\n",
    "    X_train = np.random.randn(1000, 10)\n",
    "    y_train = np.random.randint(0, 2, size=(1000,))\n",
    "    X_val = np.random.randn(200, 10)\n",
    "    y_val = np.random.randint(0, 2, size=(200,))\n",
    "\n",
    "    X_train_t = torch.tensor(X_train, dtype=torch.float32)\n",
    "    y_train_t = torch.tensor(y_train, dtype=torch.long)\n",
    "    X_val_t = torch.tensor(X_val, dtype=torch.float32)\n",
    "    y_val_t = torch.tensor(y_val, dtype=torch.long)\n",
    "\n",
    "    train_dataset = TensorDataset(X_train_t, y_train_t)\n",
    "    val_dataset = TensorDataset(X_val_t, y_val_t)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=256, shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader\n",
    "\n",
    "# Federated learning setup\n",
    "def main():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Example data\n",
    "    train_loader, val_loader = load_data()\n",
    "\n",
    "    # Dynamically determine input and output dimensions from the data\n",
    "    input_dim = next(iter(train_loader))[0].shape[1]  # number of features\n",
    "    num_classes = 2  # For binary classification, adjust if needed\n",
    "\n",
    "    model = SimpleMLP(input_dim=input_dim, hidden_dim=64, num_classes=num_classes).to(device)\n",
    "\n",
    "    client = FLClient(model, train_loader, val_loader, device)\n",
    "    fl.client.start_client(\n",
    "    server_address=\"localhost:8080\",\n",
    "    client=client.to_client()\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
